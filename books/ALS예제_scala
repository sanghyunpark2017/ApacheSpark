



/home/user/spark-2.3.0-bin-hadoop2.7/bin/spark-shell  --executor-memory 2G --total-executor-cores 40


import org.apache.spark.ml.evaluation.RegressionEvaluator
import org.apache.spark.ml.recommendation.ALS




case class Rating(userId: Int, movieId: Int, rating: Float, timestamp: Long)

def parseRating(str: String): Rating = {
  val fields = str.split("\t")
  assert(fields.size == 4)
  Rating(fields(0).toInt, fields(1).toInt, fields(2).toFloat, fields(3).toLong)
}



val ratings = spark.read.textFile("/u.data").map(parseRating).toDF()


ratings.first()
ratings.count()


val Array(training, test) = ratings.randomSplit(Array(0.8, 0.2))

training.count()
test.count()



val als = new ALS().setMaxIter(5).setRegParam(0.01).setUserCol("userId").setItemCol("movieId").setRatingCol("rating")

val model = als.fit(training)


model.userFactors.take(2)

model.itemFactors.take(2)



model.setColdStartStrategy("drop")

val predictions = model.transform(test)



val evaluator = new RegressionEvaluator().setMetricName("rmse").setLabelCol("rating").setPredictionCol("prediction")

val rmse = evaluator.evaluate(predictions)

println(s"Root-mean-square error = $rmse")



#Generate top 10 movie recommendations for each user
val userRecs = model.recommendForAllUsers(10)


#Generate top 10 user recommendations for each movie
val movieRecs = model.recommendForAllItems(10)


#Generate top 10 movie recommendations for a specified set of users
val users = ratings.select(als.getUserCol).distinct().limit(3)
val userSubsetRecs = model.recommendForUserSubset(users, 10)

userSubsetRecs.show(5, false)




#Generate top 10 user recommendations for a specified set of movies
val movies = ratings.select(als.getItemCol).distinct().limit(3)
val movieSubSetRecs = model.recommendForItemSubset(movies, 10)

movieSubSetRecs.show(5, false)





